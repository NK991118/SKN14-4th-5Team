# c:/Workspaces/Personal_Anything/3rd_to_4th/fourth_project/create_faiss_index.py (ìƒˆ íŒŒì¼)

import os
import json
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document

# .env íŒŒì¼ì—ì„œ OPENAI_API_KEYë¥¼ ë¶ˆëŸ¬ì™€
load_dotenv()

# í•„ìš”í•œ íŒŒì¼ ë° í´ë” ê²½ë¡œ ì„¤ì •
JSON_DATA_DIR = os.path.join('data', 'json')
FAISS_INDEX_DIR = os.path.join('data', 'faiss')

def create_and_save_faiss_index():
    """
    JSON íŒŒì¼ë“¤ì„ ì½ì–´ì„œ Document ê°ì²´ë¡œ ë§Œë“¤ê³ ,
    OpenAI ìž„ë² ë”©ì„ ì‚¬ìš©í•˜ì—¬ FAISS ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ê³  ì €ìž¥í•©ë‹ˆë‹¤.
    """
    print(f"--- '{JSON_DATA_DIR}' í´ë”ì˜ JSON ë°ì´í„°ë¡œ FAISS ì¸ë±ìŠ¤ ìƒì„±ì„ ì‹œìž‘í•©ë‹ˆë‹¤. ---")
    
    all_documents = []
    # data/json í´ë” ì•ˆì˜ ëª¨ë“  json íŒŒì¼ì„ ìˆœíšŒ
    for filename in os.listdir(JSON_DATA_DIR):
        if filename.endswith(".json"):
            filepath = os.path.join(JSON_DATA_DIR, filename)
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # íŒŒì¼ëª…ì—ì„œ question_id ì¶”ì¶œ (ì˜ˆ: khu_2023_1.json -> khu_2023_1)
            question_id = os.path.splitext(filename)[0]

            # ê° ì½˜í…ì¸ (ì±„ì ê¸°ì¤€, ëª¨ë²”ë‹µì•ˆ)ë¥¼ ë³„ê°œì˜ Document ê°ì²´ë¡œ ë§Œë“¤ì–´ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            if data.get("grading_criteria"):
                all_documents.append(Document(
                    page_content=data["grading_criteria"],
                    metadata={"source_type": "ì±„ì ê¸°ì¤€", "question_id": question_id}
                ))
            if data.get("sample_answer"):
                all_documents.append(Document(
                    page_content=data["sample_answer"],
                    metadata={"source_type": "ëª¨ë²”ë‹µì•ˆ", "question_id": question_id}
                ))
            print(f"âœ… '{filename}' ì²˜ë¦¬ ì™„ë£Œ.")

    if not all_documents:
        print("[ì˜¤ë¥˜] ì²˜ë¦¬í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. data/json í´ë”ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return

    print(f"\nì´ {len(all_documents)}ê°œì˜ ë¬¸ì„œ ì¡°ê°ì„ ìž„ë² ë”©í•˜ì—¬ FAISS ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
    print("(ë¬¸ì„œ ì–‘ì— ë”°ë¼ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. OpenAI APIë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.)")
    
    # OpenAI ìž„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    
    # Document ë¦¬ìŠ¤íŠ¸ì™€ ìž„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•´ FAISS ë²¡í„° DB ìƒì„±
    faiss_db = FAISS.from_documents(all_documents, embeddings)
    
    # ìƒì„±ëœ ì¸ë±ìŠ¤ë¥¼ data/faiss í´ë”ì— ì €ìž¥
    faiss_db.save_local(FAISS_INDEX_DIR)
    
    print(f"\nðŸŽ‰ FAISS ì¸ë±ìŠ¤ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print(f" -> ì €ìž¥ ìœ„ì¹˜: '{FAISS_INDEX_DIR}'")


if __name__ == "__main__":
    create_and_save_faiss_index()